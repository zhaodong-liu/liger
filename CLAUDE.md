# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Overview

This repository implements "Unifying Generative and Dense Retrieval for Sequential Recommendation" (Liger), a hybrid recommendation system that combines generative retrieval with dense retrieval. The codebase trains models on sequential recommendation datasets (Amazon, Steam) using semantic IDs generated by RQ-VAE (Residual Quantized Variational Autoencoder).

## Setup

```bash
# Create and activate conda environment
conda env create -f env.yml
conda activate liger

# Install PyTorch with CUDA support
pip install torch==2.6.0+cu126 --index-url https://download.pytorch.org/whl/cu126
```

## Running Experiments

### Main Training Command

All experiments use Hydra for configuration management. The main entry point is `run.py`:

```bash
python run.py \
    dataset=amazon \
    dataset.name=Beauty \
    seed=42 \
    device_id=0 \
    method=setting \
    test_method=liger \
    experiment_id="liger_Beauty"
```

### Pre-defined Scripts

- **Liger (hybrid method)**: `bash scripts/ours.sh`
- **TIGER baseline (generative only)**: `bash scripts/tiger.sh`
- **Ablation studies**: `bash scripts/ablation.sh`

### Common Parameters

- `dataset`: Dataset type config (`amazon` or `steam`)
- `dataset.name`: Specific dataset name (`Beauty`, `Toys_and_Games`, `Sports_and_Outdoors`, `steam`)
- `method`: Method configuration (`base` for TIGER, `setting` for Liger)
- `test_method`: Determines evaluation mode (`tiger` or `liger`)
- `device_id`: GPU device ID
- `seed`: Random seed for reproducibility

## Architecture

### Pipeline Flow

The training pipeline (run.py:62-136) follows this sequence:

1. **Data Preprocessing** (`ID_generation/preprocessing/data_process.py`): Downloads and processes raw datasets
2. **Semantic ID Generation** (`ID_generation/train_rqvae.py`): Trains RQ-VAE to compress item embeddings into semantic IDs
3. **Main Training** (`src/training.py`): Trains the T5-based sequential recommendation model

### Key Components

**RQ-VAE (Residual Quantized VAE)**
- Location: `ID_generation/rqvae/`
- Purpose: Compresses item content embeddings (768-dim from Sentence-T5) into hierarchical semantic IDs
- Configuration: 3-layer quantizer with codebook size 256, plus additional unique ID layer
- Output: Saved to `ID_generation/ID/{dataset}_{model}_{seed}.pkl`

**TIGER Model** (`src/tiger.py:54`)
- Extends `T5ForConditionalGeneration` with custom embedding projections
- Supports both semantic ID prediction (generative retrieval) and embedding prediction (dense retrieval)
- Key features:
  - Positional embeddings for semantic codes and item positions
  - Optional MLP projection for item embeddings
  - Dual-head architecture for hybrid retrieval

**Data Loading** (`src/load_data.py`)
- Converts user sequences into training examples
- Splits data into train/val/test with in-set and cold-start items
- Handles semantic ID expansion and embedding lookups
- Data format: Each example contains input sequence, labels (IDs and semantic IDs), and embeddings

**Training** (`src/training.py:275`)
- Trains with combined loss: `loss = sid_loss_weight * generative_loss + embedding_loss_weight * dense_loss`
- TIGER baseline: `sid_loss_weight=1, embedding_loss_weight=0`
- Liger method: `sid_loss_weight=1, embedding_loss_weight=1`
- Optimizer: AdamW with gradient clipping (norm=1.0)
- Scheduler: Configurable warmup + linear decay

**Evaluation** (`src/evaluation.py`)
- Three evaluation modes:
  - `genret`: Generative retrieval only
  - `dense`: Dense retrieval only
  - `uni`: Hybrid (retrieve K candidates via generative, rerank with dense)
- Metrics: Recall@k and NDCG@k for in-set and cold-start items
- Hybrid evaluation varies K = [20, 40, 60, 80, 100]; paper reports K=20 by default

### Configuration System

Hydra configs in `configs/`:
- `main.yaml`: Root config with defaults
- `dataset/`: Dataset-specific configs (amazon.yaml, steam.yaml)
- `method/`: Method configs
  - `base.yaml`: TIGER baseline (generative only)
  - `setting.yaml`: Liger method (hybrid generative + dense)
- `logging/wandb.yaml`: W&B logging configuration

Method configurations control:
- `flag_add_input_embedding`: Add learnable projection for item embeddings as input
- `flag_use_output_embedding`: Enable dense retrieval head
- `sid_loss_weight` / `embedding_loss_weight`: Balance generative vs dense loss
- `include_user_id`: Include user ID tokens (hashing trick to 2000 tokens)

## Logging

Results are logged to Weights & Biases with the following metric naming:
- Format: `{retrieval_method}_{in/cold}_{val/test}/{Recall|NDCG}@k`
- Examples:
  - `genret_in_test/Recall@10`: Generative retrieval on in-set test items
  - `dense_cold_test/NDCG@10`: Dense retrieval on cold-start test items
  - `uni_in_test/Gen20_Recall@10`: Hybrid with K=20 candidates on in-set items

To modify logging settings, edit `configs/logging/wandb.yaml`.

## Development Notes

**Semantic ID Structure**
- RQ-VAE produces 3-layer codes: `[code1, code2, code3]` each in range [0, 255]
- Additional unique ID is appended to resolve collisions: `[code1, code2, code3, unique_id]`
- IDs are expanded for T5 vocabulary: `code_i -> codebook_size * i + code_i + 1`
- Vocabulary structure: `[user_tokens(0-1999)] + [semantic_codes] + [last_layer_codes] + [pad, eos]`

**Data Splits**
- Cold-start items: Items appearing only in val/test sequences (not in training history)
- In-set items: Items that appeared during training
- Split logic in `src/load_data.py:195-202`: Second-to-last item goes to val, last item to test

**Model Checkpointing**
- Training checkpoint: `{output_path}/ckpt.pt` (includes optimizer state)
- Best model: `{output_path}/results/ckpt_best.pt` (model weights only)
- Checkpoints saved based on validation NDCG@10
- Early stopping: Patience parameter in trainer config

**Resuming Training**
If `ckpt.pt` exists, training automatically resumes from the last epoch (run.py loads checkpoint in src/training.py:489-507).

## Common Issues

**Out of Memory**: Reduce `batch_size` in dataset YAML config under `TIGER.trainer.batch_size`

**Missing Semantic IDs**: If semantic ID file doesn't exist, RQ-VAE training will run automatically. Training takes time depending on dataset size.

**Dataset Download**: First run downloads datasets via `wget`. Ensure internet connection and adequate disk space.
